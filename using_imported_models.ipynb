{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the following for working with NILM dataset\n",
    "from nilmtk.dataset import DataSet\n",
    "from nilmtk.metergroup import MeterGroup\n",
    "import pandas as pd\n",
    "from nilmtk.losses import *\n",
    "\n",
    "# Import the following for working with the data in general\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import datetime\n",
    "from IPython.display import clear_output\n",
    "import pickle\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class API():\n",
    "\n",
    "    \"\"\"\n",
    "    The API ia designed for rapid experimentation with NILM Algorithms.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,params):\n",
    "        \"\"\"\n",
    "        Initialize the API with default parameters and then start the experiment.\n",
    "        \"\"\"\n",
    "\n",
    "        self.appliances = []\n",
    "        self.train_submeters = []\n",
    "        self.train_mains = pd.DataFrame()\n",
    "        self.test_submeters = []\n",
    "        self.test_mains = pd.DataFrame()\n",
    "        self.gt_overall = {}\n",
    "        self.pred_overall = {}\n",
    "        self.classifiers=[]\n",
    "        self.errors = []\n",
    "        self.errors_keys = []\n",
    "        self.power = params['power']\n",
    "        for elems in params['appliances']:\n",
    "            self.appliances.append(elems)\n",
    "\n",
    "        self.train_datasets_dict = params['train']['datasets']\n",
    "        self.test_datasets_dict = params['test']['datasets']\n",
    "        self.metrics = params['test']['metrics']\n",
    "        self.methods = params['methods']\n",
    "        self.sample_period = params.get(\"sample_rate\", 1)\n",
    "        self.artificial_aggregate = params.get('artificial_aggregate', False)\n",
    "        self.chunk_size = params.get('chunk_size', None)\n",
    "        self.display_predictions = params.get('display_predictions', False)\n",
    "        self.DROP_ALL_NANS = params.get(\"DROP_ALL_NANS\", True)\n",
    "        self.site_only = params.get('site_only',False)\n",
    "        self.experiment()\n",
    "        \n",
    "\n",
    "    def experiment(self):\n",
    "        \"\"\"\n",
    "        Calls the Experiments with the specified parameters\n",
    "        \"\"\"\n",
    "\n",
    "        self.store_classifier_instances()\n",
    "        d=self.train_datasets_dict\n",
    "\n",
    "        for model_name, clf in self.classifiers:\n",
    "            # If the model is a neural net, it has an attribute n_epochs, Ex: DAE, Seq2Point\n",
    "            print (\"Started training for \",clf.MODEL_NAME)\n",
    "\n",
    "            # If the model has the filename specified for loading the pretrained model, then we don't need to load training data\n",
    "\n",
    "            if hasattr(clf,'load_model_path'):\n",
    "                if clf.load_model_path:\n",
    "                    print (clf.MODEL_NAME,\" is loading the pretrained model\")\n",
    "                    continue\n",
    "\n",
    "            # if user wants to train chunk wise\n",
    "            if self.chunk_size:\n",
    "                # If the classifier supports chunk wise training\n",
    "                if clf.chunk_wise_training:\n",
    "                    # if it has an attribute n_epochs. Ex: neural nets. Then it is trained chunk wise for every wise\n",
    "                    if hasattr(clf,'n_epochs'):\n",
    "                        n_epochs = clf.n_epochs\n",
    "                        clf.n_epochs = 1\n",
    "                    else:\n",
    "                        # If it doesn't have the attribute n_epochs, this is executed. Ex: Mean, Zero\n",
    "                        n_epochs = 1\n",
    "                    # Training on those many chunks for those many epochs\n",
    "                    print (\"Chunk wise training for \",clf.MODEL_NAME)\n",
    "                    for i in range(n_epochs):\n",
    "                        self.train_chunk_wise(clf, d, i)\n",
    "\n",
    "                else:\n",
    "                    print (\"Joint training for \",clf.MODEL_NAME)\n",
    "                    self.train_jointly(clf,d)            \n",
    "\n",
    "            # if it doesn't support chunk wise training\n",
    "            else:\n",
    "                print (\"Joint training for \",clf.MODEL_NAME)\n",
    "                self.train_jointly(clf,d)            \n",
    "\n",
    "            print (\"Finished training for \",clf.MODEL_NAME)\n",
    "            clear_output()\n",
    "\n",
    "        d=self.test_datasets_dict\n",
    "\n",
    "        if self.chunk_size:\n",
    "            print (\"Chunk Wise Testing for all algorithms\")\n",
    "            # It means that, predictions can also be done on chunks\n",
    "            self.test_chunk_wise(d)\n",
    "\n",
    "        else:\n",
    "            print (\"Joint Testing for all algorithms\")\n",
    "            self.test_jointly(d)\n",
    "\n",
    "    def train_chunk_wise(self, clf, d, current_epoch):\n",
    "        \"\"\"\n",
    "        This function loads the data from buildings and datasets with the specified chunk size and trains on each of them. \n",
    "        \"\"\"\n",
    "            \n",
    "        for dataset in d:\n",
    "            # Loading the dataset\n",
    "            print(\"Loading data for \",dataset, \" dataset\")          \n",
    "            for building in d[dataset]['buildings']:\n",
    "                # Loading the building\n",
    "                train=DataSet(d[dataset]['path'])\n",
    "                print(\"Loading building ... \",building)\n",
    "                train.set_window(start=d[dataset]['buildings'][building]['start_time'],end=d[dataset]['buildings'][building]['end_time'])\n",
    "                mains_iterator = train.buildings[building].elec.mains().load(chunksize = self.chunk_size, physical_quantity='power', ac_type = self.power['mains'], sample_period=self.sample_period)\n",
    "                appliance_iterators = [train.buildings[building].elec[app_name].load(chunksize = self.chunk_size, physical_quantity='power', ac_type=self.power['appliance'], sample_period=self.sample_period) for app_name in self.appliances]\n",
    "                print(train.buildings[building].elec.mains())\n",
    "                for chunk_num,chunk in enumerate (train.buildings[building].elec.mains().load(chunksize = self.chunk_size, physical_quantity='power', ac_type = self.power['mains'], sample_period=self.sample_period)):\n",
    "                    # Loading the chunk for the specifeid building\n",
    "                    #Dummry loop for executing on outer level. Just for looping till end of a chunk\n",
    "                    print(\"Starting enumeration..........\")\n",
    "                    train_df = next(mains_iterator)\n",
    "                    appliance_readings = []\n",
    "                    for i in appliance_iterators:\n",
    "                        try:\n",
    "                            appliance_df = next(i)\n",
    "                        except StopIteration:\n",
    "                            appliance_df = pd.DataFrame()\n",
    "                        appliance_readings.append(appliance_df)\n",
    "\n",
    "                    if self.DROP_ALL_NANS:\n",
    "                        train_df, appliance_readings = self.dropna(train_df, appliance_readings)\n",
    "                    \n",
    "                    if self.artificial_aggregate:\n",
    "                        print (\"Creating an Artificial Aggregate\")\n",
    "                        train_df = pd.DataFrame(np.zeros(appliance_readings[0].shape),index = appliance_readings[0].index,columns=appliance_readings[0].columns)\n",
    "                        for app_reading in appliance_readings:\n",
    "                            train_df+=app_reading\n",
    "                    train_appliances = []\n",
    "\n",
    "                    for cnt,i in enumerate(appliance_readings):\n",
    "                        train_appliances.append((self.appliances[cnt],[i]))\n",
    "\n",
    "                    self.train_mains = [train_df]\n",
    "                    self.train_submeters = train_appliances\n",
    "                    clf.partial_fit(self.train_mains, self.train_submeters, current_epoch)\n",
    "                \n",
    "\n",
    "        print(\"...............Finished the Training Process ...................\")\n",
    "\n",
    "    def test_chunk_wise(self,d):\n",
    "\n",
    "        print(\"...............Started  the Testing Process ...................\")\n",
    "\n",
    "        for dataset in d:\n",
    "            print(\"Loading data for \",dataset, \" dataset\")\n",
    "            for building in d[dataset]['buildings']:\n",
    "                test=DataSet(d[dataset]['path'])\n",
    "                test.set_window(start=d[dataset]['buildings'][building]['start_time'],end=d[dataset]['buildings'][building]['end_time'])\n",
    "                mains_iterator = test.buildings[building].elec.mains().load(chunksize = self.chunk_size, physical_quantity='power', ac_type = self.power['mains'], sample_period=self.sample_period)\n",
    "                appliance_iterators = [test.buildings[building].elec[app_name].load(chunksize = self.chunk_size, physical_quantity='power', ac_type=self.power['appliance'], sample_period=self.sample_period) for app_name in self.appliances]\n",
    "                for chunk_num,chunk in enumerate (test.buildings[building].elec.mains().load(chunksize = self.chunk_size, physical_quantity='power', ac_type = self.power['mains'], sample_period=self.sample_period)):\n",
    "                    test_df = next(mains_iterator)\n",
    "                    appliance_readings = []\n",
    "                    for i in appliance_iterators:\n",
    "                        try:\n",
    "                            appliance_df = next(i)\n",
    "                        except StopIteration:\n",
    "                            appliance_df = pd.DataFrame()\n",
    "\n",
    "                        appliance_readings.append(appliance_df)\n",
    "\n",
    "                    if self.DROP_ALL_NANS:\n",
    "                        test_df, appliance_readings = self.dropna(test_df, appliance_readings)\n",
    "\n",
    "                    if self.artificial_aggregate:\n",
    "                        print (\"Creating an Artificial Aggregate\")\n",
    "                        test_df = pd.DataFrame(np.zeros(appliance_readings[0].shape),index = appliance_readings[0].index,columns=appliance_readings[0].columns)\n",
    "                        for app_reading in appliance_readings:\n",
    "                            test_df+=app_reading\n",
    "\n",
    "                    test_appliances = []\n",
    "\n",
    "                    for cnt,i in enumerate(appliance_readings):\n",
    "                        test_appliances.append((self.appliances[cnt],[i]))\n",
    "\n",
    "                    self.test_mains = [test_df]\n",
    "                    self.test_submeters = test_appliances\n",
    "                    print(\"Results for Dataset {dataset} Building {building} Chunk {chunk_num}\".format(dataset=dataset,building=building,chunk_num=chunk_num))\n",
    "                    self.storing_key = str(dataset) + \"_\" + str(building) + \"_\" + str(chunk_num) \n",
    "                    self.call_predict(self.classifiers, test.metadata['timezone'])\n",
    "\n",
    "\n",
    "    def train_jointly(self,clf,d):\n",
    "\n",
    "        # This function has a few issues, which should be addressed soon\n",
    "        print(\"............... Loading Data for training ...................\")\n",
    "        # store the train_main readings for all buildings\n",
    "        self.train_mains = []\n",
    "        self.train_submeters = [[] for i in range(len(self.appliances))]\n",
    "        for dataset in d:\n",
    "            print(\"Loading data for \",dataset, \" dataset\")\n",
    "            train=DataSet(d[dataset]['path'])\n",
    "            for building in d[dataset]['buildings']:\n",
    "                print(\"Loading building ... \",building)\n",
    "                train.set_window(start=d[dataset]['buildings'][building]['start_time'],end=d[dataset]['buildings'][building]['end_time'])\n",
    "                train_df = next(train.buildings[building].elec.mains().load(physical_quantity='power', ac_type=self.power['mains'], sample_period=self.sample_period))\n",
    "                train_df = train_df[[list(train_df.columns)[0]]]\n",
    "                appliance_readings = []\n",
    "                \n",
    "                for appliance_name in self.appliances:\n",
    "                    appliance_df = next(train.buildings[building].elec[appliance_name].load(physical_quantity='power', ac_type=self.power['appliance'], sample_period=self.sample_period))\n",
    "                    appliance_df = appliance_df[[list(appliance_df.columns)[0]]]\n",
    "                    appliance_readings.append(appliance_df)\n",
    "\n",
    "                if self.DROP_ALL_NANS:\n",
    "                    train_df, appliance_readings = self.dropna(train_df, appliance_readings)\n",
    "\n",
    "                if self.artificial_aggregate:\n",
    "                    print (\"Creating an Artificial Aggregate\")\n",
    "                    train_df = pd.DataFrame(np.zeros(appliance_readings[0].shape),index = appliance_readings[0].index,columns=appliance_readings[0].columns)\n",
    "                    for app_reading in appliance_readings:\n",
    "                        train_df+=app_reading\n",
    "\n",
    "                self.train_mains.append(train_df)\n",
    "                for i,appliance_name in enumerate(self.appliances):\n",
    "                    self.train_submeters[i].append(appliance_readings[i])\n",
    "\n",
    "        appliance_readings = []\n",
    "        for i,appliance_name in enumerate(self.appliances):\n",
    "            appliance_readings.append((appliance_name, self.train_submeters[i]))\n",
    "\n",
    "        self.train_submeters = appliance_readings   \n",
    "\n",
    "        clf.partial_fit(self.train_mains,self.train_submeters)\n",
    "\n",
    "    \n",
    "    def test_jointly(self,d):\n",
    "        # store the test_main readings for all buildings\n",
    "        for dataset in d:\n",
    "            print(\"Loading data for \",dataset, \" dataset\")\n",
    "            test=DataSet(d[dataset]['path'])\n",
    "            for building in d[dataset]['buildings']:\n",
    "                test.set_window(start=d[dataset]['buildings'][building]['start_time'],end=d[dataset]['buildings'][building]['end_time'])\n",
    "                test_mains=next(test.buildings[building].elec.mains().load(physical_quantity='power', ac_type=self.power['mains'], sample_period=self.sample_period))\n",
    "                if self.DROP_ALL_NANS and self.site_only:\n",
    "                    test_mains, _= self.dropna(test_mains,[])\n",
    "\n",
    "                if self.site_only != True:\n",
    "                    appliance_readings=[]\n",
    "\n",
    "                    for appliance in self.appliances:\n",
    "                        test_df=next((test.buildings[building].elec[appliance].load(physical_quantity='power', ac_type=self.power['appliance'], sample_period=self.sample_period)))\n",
    "                        appliance_readings.append(test_df)\n",
    "                    \n",
    "                    if self.DROP_ALL_NANS:\n",
    "                        test_mains , appliance_readings = self.dropna(test_mains,appliance_readings)\n",
    "                \n",
    "                    if self.artificial_aggregate:\n",
    "                        print (\"Creating an Artificial Aggregate\")\n",
    "                        test_mains = pd.DataFrame(np.zeros(appliance_readings[0].shape),index = appliance_readings[0].index,columns=appliance_readings[0].columns)\n",
    "                        for app_reading in appliance_readings:\n",
    "                            test_mains+=app_reading\n",
    "                    for i, appliance_name in enumerate(self.appliances):\n",
    "                        self.test_submeters.append((appliance_name,[appliance_readings[i]]))\n",
    "\n",
    "                self.test_mains = [test_mains]\n",
    "                self.storing_key = str(dataset) + \"_\" + str(building) \n",
    "                self.call_predict(self.classifiers, test.metadata[\"timezone\"])\n",
    "\n",
    "\n",
    "    def dropna(self,mains_df, appliance_dfs=[]):\n",
    "        \"\"\"\n",
    "        Drops the missing values in the Mains reading and appliance readings and returns consistent data by copmuting the intersection\n",
    "        \"\"\"\n",
    "        print (\"Dropping missing values\")\n",
    "\n",
    "        # The below steps are for making sure that data is consistent by doing intersection across appliances\n",
    "        mains_df = mains_df.dropna()\n",
    "        ix = mains_df.index\n",
    "        mains_df = mains_df.loc[ix]\n",
    "        for i in range(len(appliance_dfs)):\n",
    "            appliance_dfs[i] = appliance_dfs[i].dropna()\n",
    "    \n",
    "        for  app_df in appliance_dfs:\n",
    "            ix = ix.intersection(app_df.index)\n",
    "        mains_df = mains_df.loc[ix]\n",
    "        new_appliances_list = []\n",
    "        for app_df in appliance_dfs:\n",
    "            new_appliances_list.append(app_df.loc[ix])\n",
    "        return mains_df,new_appliances_list\n",
    "    \n",
    "    \n",
    "    def store_classifier_instances(self):\n",
    "\n",
    "        \"\"\"\n",
    "        This function is reponsible for initializing the models with the specified model parameters\n",
    "        \"\"\"\n",
    "        for name in self.methods:\n",
    "            try:\n",
    "                                \n",
    "                clf=self.methods[name]\n",
    "                self.classifiers.append((name,clf))\n",
    "\n",
    "            except Exception as e:\n",
    "                print (\"\\n\\nThe method {model_name} specied does not exist. \\n\\n\".format(model_name=name))\n",
    "                print (e)\n",
    "    \n",
    "    def call_predict(self, classifiers, timezone):\n",
    "\n",
    "        \"\"\"\n",
    "        This functions computers the predictions on the self.test_mains using all the trained models and then compares different learn't models using the metrics specified\n",
    "        \"\"\"\n",
    "        \n",
    "        pred_overall={}\n",
    "        gt_overall={}           \n",
    "        for name,clf in classifiers:\n",
    "            gt_overall,pred_overall[name]=self.predict(clf,self.test_mains,self.test_submeters, self.sample_period, timezone)\n",
    "\n",
    "        self.gt_overall=gt_overall\n",
    "        self.pred_overall=pred_overall\n",
    "        if self.site_only != True:\n",
    "            if gt_overall.size==0:\n",
    "                print (\"No samples found in ground truth\")\n",
    "                return None\n",
    "            for metric in self.metrics:\n",
    "                try:\n",
    "                    loss_function = globals()[metric]                \n",
    "                except:\n",
    "                    print (\"Loss function \",metric, \" is not supported currently!\")\n",
    "                    continue\n",
    "\n",
    "                computed_metric={}\n",
    "                for clf_name,clf in classifiers:\n",
    "                    computed_metric[clf_name] = self.compute_loss(gt_overall, pred_overall[clf_name], loss_function)\n",
    "                computed_metric = pd.DataFrame(computed_metric)\n",
    "                print(\"............ \" ,metric,\" ..............\")\n",
    "                print(computed_metric) \n",
    "                self.errors.append(computed_metric)\n",
    "                self.errors_keys.append(self.storing_key + \"_\" + metric)\n",
    "\n",
    "\n",
    "        if self.display_predictions:\n",
    "            if self.site_only != True:\n",
    "                for i in gt_overall.columns:\n",
    "                    plt.figure()\n",
    "                    #plt.plot(self.test_mains[0],label='Mains reading')\n",
    "                    plt.plot(gt_overall[i],label='Truth')\n",
    "                    for clf in pred_overall:                \n",
    "                        plt.plot(pred_overall[clf][i],label=clf)\n",
    "                        plt.xticks(rotation=90)\n",
    "                    plt.title(i)\n",
    "                    plt.legend()\n",
    "                    plt.xlabel('Time')\n",
    "                    plt.ylabel('Power (W)')\n",
    "                plt.show()\n",
    "        \n",
    "    def predict(self, clf, test_elec, test_submeters, sample_period, timezone ):\n",
    "        print (\"Generating predictions for :\",clf.MODEL_NAME)        \n",
    "        \"\"\"\n",
    "        Generates predictions on the test dataset using the specified classifier.\n",
    "        \"\"\"\n",
    "        \n",
    "        # \"ac_type\" varies according to the dataset used. \n",
    "        # Make sure to use the correct ac_type before using the default parameters in this code.   \n",
    "        \n",
    "           \n",
    "        pred_list = clf.disaggregate_chunk(test_elec)\n",
    "\n",
    "        # It might not have time stamps sometimes due to neural nets\n",
    "        # It has the readings for all the appliances\n",
    "\n",
    "        concat_pred_df = pd.concat(pred_list,axis=0)\n",
    "\n",
    "        gt = {}\n",
    "        for meter,data in test_submeters:\n",
    "                concatenated_df_app = pd.concat(data,axis=1)\n",
    "                index = concatenated_df_app.index\n",
    "                gt[meter] = pd.Series(concatenated_df_app.values.flatten(),index=index)\n",
    "\n",
    "        gt_overall = pd.DataFrame(gt, dtype='float32')\n",
    "        pred = {}\n",
    "\n",
    "        if self.site_only ==True:\n",
    "            for app_name in concat_pred_df.columns:\n",
    "                app_series_values = concat_pred_df[app_name].values.flatten()\n",
    "                pred[app_name] = pd.Series(app_series_values)\n",
    "            pred_overall = pd.DataFrame(pred,dtype='float32')\n",
    "            pred_overall.plot(label=\"Pred\")\n",
    "            plt.title('Disaggregated Data')\n",
    "            plt.legend()\n",
    "\n",
    "        else:\n",
    "            for app_name in concat_pred_df.columns:\n",
    "                app_series_values = concat_pred_df[app_name].values.flatten()\n",
    "                # Neural nets do extra padding sometimes, to fit, so get rid of extra predictions\n",
    "                app_series_values = app_series_values[:len(gt_overall[app_name])]\n",
    "                pred[app_name] = pd.Series(app_series_values, index = gt_overall.index)\n",
    "            pred_overall = pd.DataFrame(pred,dtype='float32')\n",
    "        \n",
    "        return gt_overall, pred_overall\n",
    "\n",
    "\n",
    "    # metrics\n",
    "    def compute_loss(self,gt,clf_pred, loss_function):\n",
    "        error = {}\n",
    "        for app_name in gt.columns:\n",
    "            error[app_name] = loss_function(gt[app_name],clf_pred[app_name])\n",
    "        return pd.Series(error)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from pickle file\n",
    "def import_model(filename):\n",
    "    with open(filename, \"rb\") as pickle_in:\n",
    "        model = pickle.load(pickle_in)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-04-22 16:40:28         4746\n",
      "metadata.json                                  2024-04-22 16:40:28           64\n",
      "variables.h5                                   2024-04-22 16:40:28      5409952\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\conv1d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_4\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\dropout_1\n",
      "......vars\n",
      "...layers\\dropout_2\n",
      "......vars\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-04-22 16:40:28         4746\n",
      "metadata.json                                  2024-04-22 16:40:28           64\n",
      "variables.h5                                   2024-04-22 16:40:28      5409952\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\conv1d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_4\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\dropout_1\n",
      "......vars\n",
      "...layers\\dropout_2\n",
      "......vars\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-04-22 16:40:28         4746\n",
      "metadata.json                                  2024-04-22 16:40:28           64\n",
      "variables.h5                                   2024-04-22 16:40:28      5409952\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\conv1d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_4\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\dropout_1\n",
      "......vars\n",
      "...layers\\dropout_2\n",
      "......vars\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-04-22 16:40:28         4746\n",
      "metadata.json                                  2024-04-22 16:40:28           64\n",
      "variables.h5                                   2024-04-22 16:40:28      5409952\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\conv1d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_4\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\dropout_1\n",
      "......vars\n",
      "...layers\\dropout_2\n",
      "......vars\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-04-22 16:40:28         4746\n",
      "metadata.json                                  2024-04-22 16:40:28           64\n",
      "variables.h5                                   2024-04-22 16:40:28      5409952\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\conv1d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_4\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\dropout_1\n",
      "......vars\n",
      "...layers\\dropout_2\n",
      "......vars\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-04-22 16:40:28         4746\n",
      "metadata.json                                  2024-04-22 16:40:28           64\n",
      "variables.h5                                   2024-04-22 16:40:28      5409952\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\conv1d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_4\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\dropout_1\n",
      "......vars\n",
      "...layers\\dropout_2\n",
      "......vars\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-04-22 16:40:28         4746\n",
      "metadata.json                                  2024-04-22 16:40:28           64\n",
      "variables.h5                                   2024-04-22 16:40:28      5409952\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\conv1d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_4\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\dropout_1\n",
      "......vars\n",
      "...layers\\dropout_2\n",
      "......vars\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-04-22 16:40:28         4746\n",
      "metadata.json                                  2024-04-22 16:40:28           64\n",
      "variables.h5                                   2024-04-22 16:40:28      5409952\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\conv1d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_4\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\dropout_1\n",
      "......vars\n",
      "...layers\\dropout_2\n",
      "......vars\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-04-22 16:40:28         4745\n",
      "metadata.json                                  2024-04-22 16:40:28           64\n",
      "variables.h5                                   2024-04-22 16:40:28     43524904\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\conv1d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_4\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\dropout_1\n",
      "......vars\n",
      "...layers\\dropout_2\n",
      "......vars\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-04-22 16:40:28         4745\n",
      "metadata.json                                  2024-04-22 16:40:28           64\n",
      "variables.h5                                   2024-04-22 16:40:28     43524904\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\conv1d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_4\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\dropout_1\n",
      "......vars\n",
      "...layers\\dropout_2\n",
      "......vars\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-04-22 16:40:30         4745\n",
      "metadata.json                                  2024-04-22 16:40:30           64\n",
      "variables.h5                                   2024-04-22 16:40:30     43524904\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\conv1d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_4\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\dropout_1\n",
      "......vars\n",
      "...layers\\dropout_2\n",
      "......vars\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-04-22 16:40:30         4745\n",
      "metadata.json                                  2024-04-22 16:40:30           64\n",
      "variables.h5                                   2024-04-22 16:40:30     43524904\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\conv1d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_4\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\dropout_1\n",
      "......vars\n",
      "...layers\\dropout_2\n",
      "......vars\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-04-22 16:40:30         4745\n",
      "metadata.json                                  2024-04-22 16:40:30           64\n",
      "variables.h5                                   2024-04-22 16:40:30     43524904\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\conv1d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_4\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\dropout_1\n",
      "......vars\n",
      "...layers\\dropout_2\n",
      "......vars\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-04-22 16:40:30         4745\n",
      "metadata.json                                  2024-04-22 16:40:30           64\n",
      "variables.h5                                   2024-04-22 16:40:30     43524904\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\conv1d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_4\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\dropout_1\n",
      "......vars\n",
      "...layers\\dropout_2\n",
      "......vars\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-04-22 16:40:30         4745\n",
      "metadata.json                                  2024-04-22 16:40:30           64\n",
      "variables.h5                                   2024-04-22 16:40:30     43524904\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\conv1d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_4\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\dropout_1\n",
      "......vars\n",
      "...layers\\dropout_2\n",
      "......vars\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-04-22 16:40:32         4745\n",
      "metadata.json                                  2024-04-22 16:40:32           64\n",
      "variables.h5                                   2024-04-22 16:40:32     43524904\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\conv1d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv1d_4\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\dropout_1\n",
      "......vars\n",
      "...layers\\dropout_2\n",
      "......vars\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n"
     ]
    }
   ],
   "source": [
    "# Import the model\n",
    "model = import_model('trained_models/6sec_99SL.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get ground truth from model\n",
    "def get_ground_truth(model):\n",
    "    gt = {}\n",
    "    for i in model.gt_overall.columns:\n",
    "        gt[i] = model.gt_overall[i]\n",
    "    return gt\n",
    "\n",
    "# Function to plot different model's prediction vs ground truth\n",
    "def plot_result(model):\n",
    "    plt.rcParams['figure.figsize'] = [15, 10]\n",
    "\n",
    "    for i in model.gt_overall.columns:\n",
    "        plt.figure()\n",
    "        # plt.plot(model.test_mains[0],label='Mains reading')\n",
    "        # plt.plot(model.gt_overall[i],label='Truth')\n",
    "        plt.plot(get_ground_truth(model)[i],label='Truth')\n",
    "        for clf in model.pred_overall:\n",
    "            plt.plot(model.pred_overall[clf][i],label=clf)\n",
    "            plt.xticks(rotation=90)\n",
    "        plt.title(i)\n",
    "        plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>physical_quantity</th>\n",
       "      <th>power</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNIX</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-11-08 10:39:18+08:00</th>\n",
       "      <td>13.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-08 10:39:24+08:00</th>\n",
       "      <td>13.231667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-08 10:39:30+08:00</th>\n",
       "      <td>23.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-08 10:39:36+08:00</th>\n",
       "      <td>21.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-08 10:39:42+08:00</th>\n",
       "      <td>20.831667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-08 17:45:54+08:00</th>\n",
       "      <td>163.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-08 17:46:00+08:00</th>\n",
       "      <td>163.143333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-08 17:46:06+08:00</th>\n",
       "      <td>163.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-08 17:46:12+08:00</th>\n",
       "      <td>162.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-08 17:46:18+08:00</th>\n",
       "      <td>163.075000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4271 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "physical_quantity               power\n",
       "type                           active\n",
       "UNIX                                 \n",
       "2022-11-08 10:39:18+08:00   13.500000\n",
       "2022-11-08 10:39:24+08:00   13.231667\n",
       "2022-11-08 10:39:30+08:00   23.520000\n",
       "2022-11-08 10:39:36+08:00   21.380000\n",
       "2022-11-08 10:39:42+08:00   20.831667\n",
       "...                               ...\n",
       "2022-11-08 17:45:54+08:00  163.208333\n",
       "2022-11-08 17:46:00+08:00  163.143333\n",
       "2022-11-08 17:46:06+08:00  163.055000\n",
       "2022-11-08 17:46:12+08:00  162.820000\n",
       "2022-11-08 17:46:18+08:00  163.075000\n",
       "\n",
       "[4271 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot_result(model)\n",
    "model.test_mains[0]\n",
    "# get_ground_truth(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = {\n",
    "    'path': 'data/mimos_6_sec.h5',\n",
    "    'buildings': {\n",
    "        # 1: {\n",
    "        #     'start_time': '2022-09-27',\n",
    "        #     'end_time': '2022-09-28'\n",
    "        # },\n",
    "        # 2: {\n",
    "        #     'start_time': '2022-09-29',\n",
    "        #     'end_time': '2022-09-30'\n",
    "        # },\n",
    "        # 3: {\n",
    "        #     'start_time': '2022-11-01',\n",
    "        #     'end_time': '2022-11-02'\n",
    "        # },\n",
    "        # 4: {\n",
    "        #     'start_time': '2022-11-07',\n",
    "        #     'end_time': '2022-11-08'\n",
    "        # },\n",
    "        5: {\n",
    "            'start_time': '2022-11-08',\n",
    "            'end_time': '2022-11-09'\n",
    "        },\n",
    "        # 6: {\n",
    "        #     'start_time': '2022-11-09',\n",
    "        #     'end_time': '2022-11-10'\n",
    "        # },\n",
    "        # 7: {\n",
    "        #     'start_time': '2022-11-10',\n",
    "        #     'end_time': '2022-11-11'\n",
    "        # }\n",
    "    }\n",
    "}\n",
    "\n",
    "model.test_jointly({'test': test_params})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nilm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
