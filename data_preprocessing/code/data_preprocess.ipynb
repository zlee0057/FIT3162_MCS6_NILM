{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all the main files of the particular day into a single CSV file\n",
    "\n",
    "# Step 1: Read all CSV files into separate DataFrames\n",
    "folder_path = \"buildings_by_date/Building 2/main\"\n",
    "file_list = os.listdir(folder_path)\n",
    "dfs = []\n",
    "\n",
    "for file_name in file_list:\n",
    "    if file_name.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(folder_path, file_name))\n",
    "        dfs.append(df)\n",
    "\n",
    "# Step 2: Merge DataFrames into a single DataFrame\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Step 3: Determine the minimum and maximum timestamps\n",
    "min_timestamp = merged_df['Timestamp'].min()\n",
    "max_timestamp = merged_df['Timestamp'].max()\n",
    "\n",
    "# Step 4: Resample DataFrame to fill in missing timestamps\n",
    "merged_df['Timestamp'] = pd.to_datetime(merged_df['Timestamp'])\n",
    "merged_df.set_index('Timestamp', inplace=True)\n",
    "merged_df = merged_df.asfreq('s')\n",
    "\n",
    "# Step 5: Replace NaN values with 0\n",
    "merged_df.fillna(0, inplace=True)\n",
    "\n",
    "# Step 6: Write merged DataFrame to a new CSV file\n",
    "merged_csv_path = \"buildings_by_date/Building 2/building_2_main_output.csv\"\n",
    "merged_df.to_csv(merged_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Timestamp  dryer\n",
      "0  2022-11-10 11:53:42   0.17\n",
      "1  2022-11-10 11:53:43   0.15\n",
      "2  2022-11-10 11:53:44   0.13\n",
      "3  2022-11-10 11:53:45   0.14\n",
      "4  2022-11-10 11:53:46   0.16\n",
      "             Timestamp  dryer  kettle\n",
      "0  2022-11-10 11:53:42   0.17     NaN\n",
      "1  2022-11-10 11:53:43   0.15     NaN\n",
      "2  2022-11-10 11:53:44   0.13     NaN\n",
      "3  2022-11-10 11:53:45   0.14     NaN\n",
      "4  2022-11-10 11:53:46   0.16     NaN\n",
      "             Timestamp  dryer  kettle  vacuum\n",
      "0  2022-11-10 11:53:42   0.17     NaN     NaN\n",
      "1  2022-11-10 11:53:43   0.15     NaN     NaN\n",
      "2  2022-11-10 11:53:44   0.13     NaN     NaN\n",
      "3  2022-11-10 11:53:45   0.14     NaN     NaN\n",
      "4  2022-11-10 11:53:46   0.16     NaN     NaN\n",
      "             Timestamp  dryer  kettle  vacuum  water_heater\n",
      "0  2022-11-10 11:53:42   0.17     NaN     NaN           NaN\n",
      "1  2022-11-10 11:53:43   0.15     NaN     NaN           NaN\n",
      "2  2022-11-10 11:53:44   0.13     NaN     NaN           NaN\n",
      "3  2022-11-10 11:53:45   0.14     NaN     NaN           NaN\n",
      "4  2022-11-10 11:53:46   0.16     NaN     NaN           NaN\n",
      "             Timestamp  dryer  kettle  vacuum  water_heater  oven\n",
      "0  2022-11-10 11:53:42   0.17     NaN     NaN           NaN   NaN\n",
      "1  2022-11-10 11:53:43   0.15     NaN     NaN           NaN   NaN\n",
      "2  2022-11-10 11:53:44   0.13     NaN     NaN           NaN   NaN\n",
      "3  2022-11-10 11:53:45   0.14     NaN     NaN           NaN   NaN\n",
      "4  2022-11-10 11:53:46   0.16     NaN     NaN           NaN   NaN\n",
      "             Timestamp  dryer  kettle  vacuum  water_heater  oven  fridge\n",
      "0  2022-11-10 11:53:42   0.17     NaN     NaN           NaN   NaN     NaN\n",
      "1  2022-11-10 11:53:43   0.15     NaN     NaN           NaN   NaN     NaN\n",
      "2  2022-11-10 11:53:44   0.13     NaN     NaN           NaN   NaN     NaN\n",
      "3  2022-11-10 11:53:45   0.14     NaN     NaN           NaN   NaN     NaN\n",
      "4  2022-11-10 11:53:46   0.16     NaN     NaN           NaN   NaN     NaN\n",
      "             Timestamp  dryer  kettle  vacuum  water_heater  oven  fridge  \\\n",
      "0  2022-11-10 11:53:42   0.17     NaN     NaN           NaN   NaN     NaN   \n",
      "1  2022-11-10 11:53:43   0.15     NaN     NaN           NaN   NaN     NaN   \n",
      "2  2022-11-10 11:53:44   0.13     NaN     NaN           NaN   NaN     NaN   \n",
      "3  2022-11-10 11:53:45   0.14     NaN     NaN           NaN   NaN     NaN   \n",
      "4  2022-11-10 11:53:46   0.16     NaN     NaN           NaN   NaN     NaN   \n",
      "\n",
      "   washing_machine  \n",
      "0            11.12  \n",
      "1            11.10  \n",
      "2            11.13  \n",
      "3            11.08  \n",
      "4            11.13  \n",
      "             Timestamp  dryer  kettle  vacuum  water_heater  oven  fridge  \\\n",
      "0  2022-11-10 11:53:42   0.17     NaN     NaN           NaN   NaN     NaN   \n",
      "1  2022-11-10 11:53:43   0.15     NaN     NaN           NaN   NaN     NaN   \n",
      "2  2022-11-10 11:53:44   0.13     NaN     NaN           NaN   NaN     NaN   \n",
      "3  2022-11-10 11:53:45   0.14     NaN     NaN           NaN   NaN     NaN   \n",
      "4  2022-11-10 11:53:46   0.16     NaN     NaN           NaN   NaN     NaN   \n",
      "\n",
      "   washing_machine  aircond  \n",
      "0            11.12      NaN  \n",
      "1            11.10      NaN  \n",
      "2            11.13      NaN  \n",
      "3            11.08      NaN  \n",
      "4            11.13      NaN  \n",
      "Consolidated CSV created for buildings_by_date/Building 7\n"
     ]
    }
   ],
   "source": [
    "# Merge the appliance files into a single CSV file\n",
    "\n",
    "# Define the path to the main folder containing building folders\n",
    "main_folder_path = 'buildings_by_date/Building 6'\n",
    "\n",
    "# List of appliance names to look for in each building folder\n",
    "appliances = [\"dryer\", \"kettle\", \"vacuum\", \"water_heater\", \"oven\", \"fridge\", \"washing_machine\", \"aircond\"]\n",
    "\n",
    "# Function to find all files that contain the appliance name in their filename\n",
    "def find_appliance_files(folder_path, appliance_name):\n",
    "    appliance_files = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if appliance_name in file and file.endswith('.csv'):\n",
    "            appliance_files.append(os.path.join(folder_path, file))\n",
    "    return appliance_files\n",
    "\n",
    "# Dictionary to hold data for each appliance\n",
    "data_frames = {}\n",
    "\n",
    "# Loop through each appliance and create an empty DataFrame\n",
    "for appliance in appliances:\n",
    "    data_frames[appliance] = pd.DataFrame({'Timestamp': [], 'Active (W)': []})\n",
    "\n",
    "# Loop through each appliance and try to find and load its data\n",
    "for appliance in appliances:\n",
    "    appliance_files = find_appliance_files(main_folder_path, appliance)\n",
    "    if appliance_files:\n",
    "        # Read all CSV files for the appliance\n",
    "        dfs = []\n",
    "        for file in appliance_files:\n",
    "            df = pd.read_csv(file, usecols=['Timestamp', 'Active (W)']).fillna(0)\n",
    "            dfs.append(df)\n",
    "        data_frames[appliance] = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Initialize a DataFrame to merge all appliance data\n",
    "consolidated_df = pd.DataFrame()\n",
    "\n",
    "# Loop through each appliance DataFrame and merge\n",
    "for appliance, df in data_frames.items():\n",
    "\n",
    "    # Rename 'Active (W)' to the appliance name for clarity\n",
    "    df = df.rename(columns={'Active (W)': appliance})\n",
    "    if consolidated_df.empty:\n",
    "        consolidated_df = df\n",
    "    else:\n",
    "        # Merge on 'Timestamp', ensuring to use an outer join to keep all timestamps\n",
    "        consolidated_df = pd.merge(consolidated_df, df, on='Timestamp', how='outer')\n",
    "\n",
    "    # Show head of each appliance file\n",
    "    print(consolidated_df.head())\n",
    "\n",
    "consolidated_df.fillna(0, inplace=True)\n",
    "\n",
    "# Save the consolidated DataFrame to a new CSV file\n",
    "consolidated_csv_path = os.path.join(main_folder_path, \"appliances_by_column.csv\")\n",
    "consolidated_df.to_csv(consolidated_csv_path, index=False)\n",
    "print(f\"Consolidated CSV created for {main_folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Timestamp  Apparent (VA)  Active (W)\n",
      "0  2022-11-08 10:39:23          23.97       13.50\n",
      "1  2022-11-08 10:39:24          23.72       13.20\n",
      "2  2022-11-08 10:39:25          23.55       13.00\n",
      "3  2022-11-08 10:39:26          24.05       13.35\n",
      "4  2022-11-08 10:39:27          23.69       13.22\n",
      "             Timestamp  kettle  vacuum  water_heater  oven  fridge  \\\n",
      "0  2022-11-08 10:39:23     0.0     0.0           0.0   0.0     0.0   \n",
      "1  2022-11-08 10:39:24     0.0     0.0           0.0   0.0     0.0   \n",
      "2  2022-11-08 10:39:25     0.0     0.0           0.0   0.0     0.0   \n",
      "3  2022-11-08 10:39:26     0.0     0.0           0.0   0.0     0.0   \n",
      "4  2022-11-08 10:39:27     0.0     0.0           0.0   0.0     0.0   \n",
      "\n",
      "   washing_machine  dryer  aircond  \n",
      "0            11.07    0.0      0.0  \n",
      "1            11.32    0.0      0.0  \n",
      "2            11.33    0.0      0.0  \n",
      "3            11.30    0.0      0.0  \n",
      "4            11.23    0.0      0.0  \n",
      "             Timestamp  Apparent (VA)  Active (W)  kettle  vacuum  \\\n",
      "0  2022-11-08 10:39:23          23.97       13.50     0.0     0.0   \n",
      "1  2022-11-08 10:39:24          23.72       13.20     0.0     0.0   \n",
      "2  2022-11-08 10:39:25          23.55       13.00     0.0     0.0   \n",
      "3  2022-11-08 10:39:26          24.05       13.35     0.0     0.0   \n",
      "4  2022-11-08 10:39:27          23.69       13.22     0.0     0.0   \n",
      "\n",
      "   water_heater  oven  fridge  washing_machine  dryer  aircond  \n",
      "0           0.0   0.0     0.0            11.07    0.0      0.0  \n",
      "1           0.0   0.0     0.0            11.32    0.0      0.0  \n",
      "2           0.0   0.0     0.0            11.33    0.0      0.0  \n",
      "3           0.0   0.0     0.0            11.30    0.0      0.0  \n",
      "4           0.0   0.0     0.0            11.23    0.0      0.0  \n"
     ]
    }
   ],
   "source": [
    "# Merge the main and appliance CSV files into a single CSV file\n",
    "\n",
    "# Path to your main CSV file\n",
    "main_csv_path = 'buildings_by_date/Building 5/building_5_main_output.csv'\n",
    "\n",
    "# Load the main CSV file\n",
    "main_df = pd.read_csv(main_csv_path)\n",
    "print(main_df.head())\n",
    "\n",
    "# Define path to the appliance CSV file\n",
    "appliance_csv_path = 'buildings_by_date/Building 5/appliances_by_column.csv'\n",
    "\n",
    "# Load the appliance CSV file\n",
    "appliances_df = pd.read_csv(appliance_csv_path)\n",
    "print(appliances_df.head())\n",
    "\n",
    "# Merge the main and appliance DataFrames on the 'Timestamp' column\n",
    "merged_df = pd.merge(main_df, appliances_df, on='Timestamp', how='outer')\n",
    "print(merged_df.head())\n",
    "\n",
    "# Fill any NaN values with 0\n",
    "merged_df.fillna(0, inplace=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_csv_path = 'mimos_final_buildings/1_sec/Building_5.csv'\n",
    "merged_df.to_csv(merged_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling Building_1.csv...\n",
      "Saved resampled file to mimos_final_buildings/3_sec\\Building_1.csv\n",
      "Resampling Building_2.csv...\n",
      "Saved resampled file to mimos_final_buildings/3_sec\\Building_2.csv\n",
      "Resampling Building_3.csv...\n",
      "Saved resampled file to mimos_final_buildings/3_sec\\Building_3.csv\n",
      "Resampling Building_4.csv...\n",
      "Saved resampled file to mimos_final_buildings/3_sec\\Building_4.csv\n",
      "Resampling Building_5.csv...\n",
      "Saved resampled file to mimos_final_buildings/3_sec\\Building_5.csv\n",
      "Resampling Building_6.csv...\n",
      "Saved resampled file to mimos_final_buildings/3_sec\\Building_6.csv\n",
      "Resampling Building_7.csv...\n",
      "Saved resampled file to mimos_final_buildings/3_sec\\Building_7.csv\n"
     ]
    }
   ],
   "source": [
    "def resample_csv(input_path, output_path, sampling_period='6s'):\n",
    "    \"\"\"Resample the dataset to a new frequency.\n",
    "\n",
    "    Parameters:\n",
    "    input_path (str): Path to the input CSV file.\n",
    "    output_path (str): Path to save the resampled CSV file.\n",
    "    sampling_period (str): New sampling frequency (default is '6s' for 6 seconds).\n",
    "    \"\"\"\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(input_path, index_col=0, parse_dates=True)\n",
    "\n",
    "    # Resample the dataset\n",
    "    resampled_df = df.resample(sampling_period).mean()\n",
    "\n",
    "    # Drop rows where all columns (except for the index) are NaN\n",
    "    resampled_df = resampled_df.dropna(how='all')\n",
    "\n",
    "    # Save the resampled dataset\n",
    "    resampled_df.to_csv(output_path)\n",
    "\n",
    "file_names = [\n",
    "    \"Building_1.csv\",\n",
    "    \"Building_2.csv\",\n",
    "    \"Building_3.csv\",\n",
    "    \"Building_4.csv\",\n",
    "    \"Building_5.csv\",\n",
    "    \"Building_6.csv\",\n",
    "    \"Building_7.csv\"\n",
    "]\n",
    "\n",
    "input_directory = \"mimos_final_buildings/1_sec\"\n",
    "output_directory = \"mimos_final_buildings/3_sec\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "for file_name in file_names:\n",
    "    input_path = os.path.join(input_directory, file_name)\n",
    "    output_path = os.path.join(output_directory, file_name)\n",
    "    print(f\"Resampling {file_name}...\")\n",
    "    resample_csv(input_path, output_path, '3s')\n",
    "    print(f\"Saved resampled file to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Duplicate Timestamps\n",
    "\n",
    "# Step 1: Read CSV files into DataFrames\n",
    "folder_path = \"buildings_by_date/Building 5/main\"\n",
    "file_names = os.listdir(folder_path)\n",
    "dfs = []\n",
    "\n",
    "for file_name in file_names:\n",
    "    if file_name.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(folder_path, file_name))\n",
    "        dfs.append(df)\n",
    "\n",
    "# Step 2: Merge DataFrames into a single DataFrame\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Step 3: Check for duplicate timestamps\n",
    "duplicates = merged_df.duplicated(subset=['Timestamp'], keep=False)\n",
    "if duplicates.any():\n",
    "    print(\"Warning: Duplicate timestamps found.\")\n",
    "    duplicate_rows = merged_df[duplicates]\n",
    "    duplicate_timestamps = duplicate_rows['Timestamp'].unique()\n",
    "    print(\"Duplicate Timestamps:\")\n",
    "    for timestamp in duplicate_timestamps:\n",
    "        print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with duplicates by summing up the values\n",
    "\n",
    "# Read the two CSV files into DataFrames\n",
    "df1 = pd.read_csv('buildings_by_date/Building 4/main/2022-11-07-17_15_17_main_output.csv')\n",
    "df2 = pd.read_csv('buildings_by_date/Building 4/main/2022-11-07-17_28_46_main_output.csv')\n",
    "\n",
    "# Merge the two DataFrames on the Timestamp column\n",
    "merged_df = pd.merge(df1, df2, on='Timestamp')\n",
    "\n",
    "# Add up the Active (W) and Apparent (W) values\n",
    "merged_df['Active (W)'] = merged_df['Active (W)_x'] + merged_df['Active (W)_y']\n",
    "merged_df['Apparent (VA)'] = merged_df['Apparent (VA)_x'] + merged_df['Apparent (VA)_y']\n",
    "\n",
    "# Drop the original Active (W) and Apparent (W) columns from the merged DataFrame\n",
    "merged_df.drop(['Active (W)_x', 'Active (W)_y', 'Apparent (VA)_x', 'Apparent (VA)_y'], axis=1, inplace=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('buildings_by_date/Building 4/main/no_more_duplicate.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change timestamp into correct format\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('buildings_by_date/Building 6/main/2022-11-09-10_00_06_main_output.csv')\n",
    "\n",
    "# Convert the Timestamp column to datetime format\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "\n",
    "# Convert the Timestamp column to the desired format\n",
    "df['Timestamp'] = df['Timestamp'].dt.strftime('%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "# Save the DataFrame back to a CSV file\n",
    "df.to_csv('output_file.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nilmtk-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
